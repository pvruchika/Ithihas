# Ithihas

This research project aims to conduct sentiment analysis on historical journals to gain insights into the emotional and psychological experiences of authors, often overlooked in traditional historical accounts. Specifically, we compare the performance of three state-of-the-art models for sentiment analysis: BERT, DistilBERT, and RoBERTa. Our hypothesis is that transformer-based models, such as these, will outperform traditional deep learning models due to their ability to capture complex relationships between words in a sentence. We aim to identify which model excels in terms of accuracy, precision, recall, and F1 score. Additionally, we investigate how the performance of these models is influenced by factors such as data pre-processing, hyperparameter tuning, and model architecture. The research findings will provide insights into the effectiveness of these models for sentiment analysis of historical journals and potentially inform decisions about which model to use in similar applications.
